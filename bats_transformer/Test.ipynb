{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4637ab5-f716-41f9-a9e7-61f886426c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vdesai/anaconda3/envs/bats/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import spacetimeformer as stf\n",
    "import pandas as pd\n",
    "\n",
    "from data import preprocess\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "stf.spacetimeformer_model.Spacetimeformer_Forecaster.add_cli(parser)\n",
    "stf.callbacks.TimeMaskedLossCallback.add_cli(parser)\n",
    "stf.data.DataModule.add_cli(parser)\n",
    "preprocess.add_cli(parser)\n",
    "\n",
    "parser.add_argument(\"--model_path\", type=str, default=\"/home/vdesai/bats/bats_transformer/models/random_seed_1.ckpt\")\n",
    "parser.add_argument(\"--filerandom\", \"-f\")\n",
    "config = parser.parse_args()\n",
    "args = config\n",
    "model_path = args.model_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac9c74ef-69cb-4b68-9e04-f4aa6c1f3c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          True\n",
      "1          True\n",
      "2          True\n",
      "3          True\n",
      "4          True\n",
      "          ...  \n",
      "114875    False\n",
      "114876    False\n",
      "114877    False\n",
      "114878    False\n",
      "114879    False\n",
      "Name: TimeInFile, Length: 114880, dtype: bool\n",
      "train_data\n",
      "         ParentDir          TimeInFile  PrecedingIntrvl  CallsPerSec  \\\n",
      "0              0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "1              0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "2              0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "3              0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "4              0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "...            ...                 ...              ...          ...   \n",
      "114875  20220720.0 1970-01-02 00:30:00           18.000     8.263117   \n",
      "114876  20220720.0 1970-01-02 01:19:00           49.104     8.263117   \n",
      "114877  20220720.0 1970-01-02 01:36:00           16.704     8.263117   \n",
      "114878  20220720.0 1970-01-02 02:36:00           14.976     8.263117   \n",
      "114879  20220720.0 1970-01-02 02:48:00           11.376     8.263117   \n",
      "\n",
      "        CallDuration         Fc     HiFreq    LowFreq    Bndwdth  FreqMaxPwr  \\\n",
      "0           0.000000   0.000000   0.000000   0.000000   0.000000    0.000000   \n",
      "1           0.000000   0.000000   0.000000   0.000000   0.000000    0.000000   \n",
      "2           0.000000   0.000000   0.000000   0.000000   0.000000    0.000000   \n",
      "3           0.000000   0.000000   0.000000   0.000000   0.000000    0.000000   \n",
      "4           0.000000   0.000000   0.000000   0.000000   0.000000    0.000000   \n",
      "...              ...        ...        ...        ...        ...         ...   \n",
      "114875      4.577047  30.195834  44.040102  16.762907  27.277195   38.471429   \n",
      "114876      3.474345  27.863433  46.568569  24.082266  22.486303   34.928032   \n",
      "114877      2.991706  27.626805  41.888079  27.550901  14.337178   40.064701   \n",
      "114878      3.982343  23.007298  39.111689  16.407980  22.703709   37.872542   \n",
      "114879      3.593837  20.292025  43.323425  14.829001  28.494424   23.184135   \n",
      "\n",
      "        ...  PreFc1000Residue  PreFc3000  PreFc3000Residue  KneeToFcResidue  \\\n",
      "0       ...          0.000000   0.000000          0.000000         0.000000   \n",
      "1       ...          0.000000   0.000000          0.000000         0.000000   \n",
      "2       ...          0.000000   0.000000          0.000000         0.000000   \n",
      "3       ...          0.000000   0.000000          0.000000         0.000000   \n",
      "4       ...          0.000000   0.000000          0.000000         0.000000   \n",
      "...     ...               ...        ...               ...              ...   \n",
      "114875  ...          0.017938  -6.773513          0.116720         0.087604   \n",
      "114876  ...          0.021237  -0.990969          0.021237         0.018707   \n",
      "114877  ...          0.031792  -6.533744          0.129777         0.101626   \n",
      "114878  ...          0.007067  -6.591697          0.037980         0.066469   \n",
      "114879  ...          0.007555  -5.983418          0.007555         0.006947   \n",
      "\n",
      "        Kn-FcCurviness  meanKn-FcCurviness  Kn-FcCurvinessTrndSlp  \\\n",
      "0             0.000000            0.000000               0.000000   \n",
      "1             0.000000            0.000000               0.000000   \n",
      "2             0.000000            0.000000               0.000000   \n",
      "3             0.000000            0.000000               0.000000   \n",
      "4             0.000000            0.000000               0.000000   \n",
      "...                ...                 ...                    ...   \n",
      "114875        0.015669            0.000234               0.005391   \n",
      "114876        0.010501            0.002100              -0.037078   \n",
      "114877        0.058338            0.000711               0.005856   \n",
      "114878       -0.108494           -0.001130               0.001739   \n",
      "114879        0.023593            0.001072              -0.002290   \n",
      "\n",
      "        MinAccpQuality  Max#CallsConsidered    Minute  \n",
      "0                  0.0                  0.0 -1.000000  \n",
      "1                  0.0                  0.0 -1.000000  \n",
      "2                  0.0                  0.0 -1.000000  \n",
      "3                  0.0                  0.0 -1.000000  \n",
      "4                  0.0                  0.0 -1.000000  \n",
      "...                ...                  ...       ...  \n",
      "114875             0.8                 32.0  0.016949  \n",
      "114876             0.8                 32.0 -0.355932  \n",
      "114877             0.8                 32.0  0.220339  \n",
      "114878             0.8                 32.0  0.220339  \n",
      "114879             0.8                 32.0  0.627119  \n",
      "\n",
      "[114880 rows x 108 columns]\n",
      "        ParentDir          TimeInFile  PrecedingIntrvl  CallsPerSec  \\\n",
      "0             0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "1             0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "2             0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "3             0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "4             0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "...           ...                 ...              ...          ...   \n",
      "91899  20220720.0 1970-01-01 02:48:00          123.264     3.142851   \n",
      "91900  20220720.0 1970-01-02 03:48:00          640.944     3.142851   \n",
      "91901  20220720.0 1970-01-02 22:12:00         1057.104     3.142851   \n",
      "91902  20220720.0 1970-01-02 22:57:00           52.272     3.142851   \n",
      "91903  20220720.0 1970-01-04 04:30:00         1767.888     3.142851   \n",
      "\n",
      "       CallDuration         Fc     HiFreq    LowFreq   Bndwdth  FreqMaxPwr  \\\n",
      "0          0.000000   0.000000   0.000000   0.000000  0.000000    0.000000   \n",
      "1          0.000000   0.000000   0.000000   0.000000  0.000000    0.000000   \n",
      "2          0.000000   0.000000   0.000000   0.000000  0.000000    0.000000   \n",
      "3          0.000000   0.000000   0.000000   0.000000  0.000000    0.000000   \n",
      "4          0.000000   0.000000   0.000000   0.000000  0.000000    0.000000   \n",
      "...             ...        ...        ...        ...       ...         ...   \n",
      "91899     18.399585  20.063281  24.544834  19.994148  4.550685   23.827839   \n",
      "91900     13.601348  18.967055  20.895082  18.881508  2.013574   18.934516   \n",
      "91901     13.312753  19.680774  21.812231  19.158955  2.653276   19.981182   \n",
      "91902      7.367039  23.218300  25.806053  22.821979  2.984074   23.779640   \n",
      "91903     17.038983  19.269117  21.623483  17.675429  3.948055   19.899771   \n",
      "\n",
      "       ...  PreFc1000Residue  PreFc3000  PreFc3000Residue  KneeToFcResidue  \\\n",
      "0      ...          0.000000   0.000000          0.000000         0.000000   \n",
      "1      ...          0.000000   0.000000          0.000000         0.000000   \n",
      "2      ...          0.000000   0.000000          0.000000         0.000000   \n",
      "3      ...          0.000000   0.000000          0.000000         0.000000   \n",
      "4      ...          0.000000   0.000000          0.000000         0.000000   \n",
      "...    ...               ...        ...               ...              ...   \n",
      "91899  ...          0.000706  -0.090170          0.001409         0.003531   \n",
      "91900  ...          0.000451  -0.105476          0.002174         0.002191   \n",
      "91901  ...          0.007536  -0.024592          0.021879         0.011434   \n",
      "91902  ...          0.000947  -0.261921          0.002305         0.002122   \n",
      "91903  ...          0.000761  -0.071098          0.001929         0.002699   \n",
      "\n",
      "       Kn-FcCurviness  meanKn-FcCurviness  Kn-FcCurvinessTrndSlp  \\\n",
      "0            0.000000            0.000000               0.000000   \n",
      "1            0.000000            0.000000               0.000000   \n",
      "2            0.000000            0.000000               0.000000   \n",
      "3            0.000000            0.000000               0.000000   \n",
      "4            0.000000            0.000000               0.000000   \n",
      "...               ...                 ...                    ...   \n",
      "91899        0.008384            0.000019              -0.000006   \n",
      "91900        0.006866            0.000057               0.000128   \n",
      "91901        0.005772            0.000015               0.000002   \n",
      "91902        0.010546            0.000079              -0.000008   \n",
      "91903        0.008013            0.000031               0.000059   \n",
      "\n",
      "       MinAccpQuality  Max#CallsConsidered    Minute  \n",
      "0                 0.0                  0.0 -1.000000  \n",
      "1                 0.0                  0.0 -1.000000  \n",
      "2                 0.0                  0.0 -1.000000  \n",
      "3                 0.0                  0.0 -1.000000  \n",
      "4                 0.0                  0.0 -1.000000  \n",
      "...               ...                  ...       ...  \n",
      "91899             0.8                 32.0  0.627119  \n",
      "91900             0.8                 32.0  0.627119  \n",
      "91901             0.8                 32.0 -0.593220  \n",
      "91902             0.8                 32.0  0.932203  \n",
      "91903             0.8                 32.0  0.016949  \n",
      "\n",
      "[91904 rows x 108 columns]\n",
      "val data\n",
      "         ParentDir          TimeInFile  PrecedingIntrvl  CallsPerSec  \\\n",
      "91904          0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "91905          0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "91906          0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "91907          0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "91908          0.0 1970-01-01 00:00:00            0.000     0.000000   \n",
      "...            ...                 ...              ...          ...   \n",
      "103387  20220720.0 1970-01-02 22:51:00           32.976    21.162869   \n",
      "103388  20220720.0 1970-01-02 23:07:00           17.712    21.162869   \n",
      "103389  20220720.0 1970-01-03 00:23:00           63.504    21.162869   \n",
      "103390  20220720.0 1970-01-03 00:44:00           20.880    21.162869   \n",
      "103391  20220720.0 1970-01-03 02:13:00           88.848    21.162869   \n",
      "\n",
      "        CallDuration         Fc     HiFreq    LowFreq    Bndwdth  FreqMaxPwr  \\\n",
      "91904       0.000000   0.000000   0.000000   0.000000   0.000000    0.000000   \n",
      "91905       0.000000   0.000000   0.000000   0.000000   0.000000    0.000000   \n",
      "91906       0.000000   0.000000   0.000000   0.000000   0.000000    0.000000   \n",
      "91907       0.000000   0.000000   0.000000   0.000000   0.000000    0.000000   \n",
      "91908       0.000000   0.000000   0.000000   0.000000   0.000000    0.000000   \n",
      "...              ...        ...        ...        ...        ...         ...   \n",
      "103387      5.867533  22.971917  47.583644  22.817610  24.766034   36.024656   \n",
      "103388      6.027046  24.520898  46.844083  24.414096  22.429988   37.317454   \n",
      "103389      3.328670  23.791754  46.130415  21.644162  24.486253   32.787968   \n",
      "103390      4.341809  29.839318  49.772488  23.629195  26.143292   32.083983   \n",
      "103391      4.053083  30.841559  48.589286  30.810235  17.779051   34.534552   \n",
      "\n",
      "        ...  PreFc1000Residue  PreFc3000  PreFc3000Residue  KneeToFcResidue  \\\n",
      "91904   ...          0.000000   0.000000          0.000000         0.000000   \n",
      "91905   ...          0.000000   0.000000          0.000000         0.000000   \n",
      "91906   ...          0.000000   0.000000          0.000000         0.000000   \n",
      "91907   ...          0.000000   0.000000          0.000000         0.000000   \n",
      "91908   ...          0.000000   0.000000          0.000000         0.000000   \n",
      "...     ...               ...        ...               ...              ...   \n",
      "103387  ...          0.161635  -5.177514          0.114493         0.140155   \n",
      "103388  ...          0.123747  -3.867698          0.092826         0.116556   \n",
      "103389  ...          0.237009  -8.152320          0.485625         0.485625   \n",
      "103390  ...          0.043455  -6.795975          0.137711         0.117877   \n",
      "103391  ...          0.022246  -3.152687          0.057269         0.021075   \n",
      "\n",
      "        Kn-FcCurviness  meanKn-FcCurviness  Kn-FcCurvinessTrndSlp  \\\n",
      "91904         0.000000            0.000000               0.000000   \n",
      "91905         0.000000            0.000000               0.000000   \n",
      "91906         0.000000            0.000000               0.000000   \n",
      "91907         0.000000            0.000000               0.000000   \n",
      "91908         0.000000            0.000000               0.000000   \n",
      "...                ...                 ...                    ...   \n",
      "103387        0.124182            0.002700               0.018627   \n",
      "103388        0.106595            0.001777               0.006268   \n",
      "103389       -0.224141           -0.002095              -0.000067   \n",
      "103390        0.053731            0.000537               0.003249   \n",
      "103391        0.095452            0.002651               0.006547   \n",
      "\n",
      "        MinAccpQuality  Max#CallsConsidered    Minute  \n",
      "91904              0.0                  0.0 -1.000000  \n",
      "91905              0.0                  0.0 -1.000000  \n",
      "91906              0.0                  0.0 -1.000000  \n",
      "91907              0.0                  0.0 -1.000000  \n",
      "91908              0.0                  0.0 -1.000000  \n",
      "...                ...                  ...       ...  \n",
      "103387             0.8                 32.0  0.728814  \n",
      "103388             0.8                 32.0 -0.762712  \n",
      "103389             0.8                 32.0 -0.220339  \n",
      "103390             0.8                 32.0  0.491525  \n",
      "103391             0.8                 32.0 -0.559322  \n",
      "\n",
      "[11488 rows x 108 columns]\n",
      "x_dim = 1, yc_dim = 106, yt_dim = 106\n"
     ]
    }
   ],
   "source": [
    "#reading dataframe\n",
    "df, max_seq_len = preprocess.preprocess(config)\n",
    "df, max_seq_len = preprocess.preprocess(config)\n",
    "bats_time_series = stf.data.CSVTimeSeries(\n",
    "                        raw_df = df,\n",
    "                        time_col_name = \"TimeInFile\",\n",
    "                        time_features = [\"minute\"],\n",
    "                        ignore_cols = [\"Filename\", \"NextDirUp\", 'Path', 'Version', 'Filter', 'Preemphasis', 'MaxSegLnght'],\n",
    "                        val_split = 0.1,\n",
    "                        test_split = 0.1\n",
    "                    )\n",
    "# create a dataloader with the bats_time_series object\n",
    "bats_dataset = stf.data.CSVTorchDset(\n",
    "                    csv_time_series = bats_time_series,\n",
    "                    split = \"train\",\n",
    "                    context_points = max_seq_len - 2,\n",
    "                    target_points = 2, \n",
    "                    time_resolution = 1\n",
    "                )\n",
    "\n",
    "x_dim = bats_time_series.time_cols.size\n",
    "yc_dim = len(bats_time_series.target_cols)\n",
    "yt_dim = len(bats_time_series.target_cols)\n",
    "\n",
    "print(f\"{x_dim = }, {yc_dim = }, {yt_dim = }\")\n",
    "\n",
    "data_module = stf.data.DataModule(\n",
    "    datasetCls = stf.data.CSVTorchDset,\n",
    "    dataset_kwargs = {\n",
    "        \"csv_time_series\": bats_time_series,\n",
    "        \"context_points\": max_seq_len - 2,\n",
    "        \"target_points\": 2,\n",
    "        \"time_resolution\": 1,\n",
    "    },\n",
    "    batch_size = config.batch_size,\n",
    "    workers = config.workers,\n",
    "    overfit = args.overfit\n",
    ")\n",
    "\n",
    "# Example DataLoader check\n",
    "train_loader = data_module.train_dataloader()\n",
    "val_loader = data_module.val_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "assert train_loader is not None, \"Training DataLoader is None\"\n",
    "assert val_loader is not None, \"Validation DataLoader is None\"\n",
    "assert test_loader is not None, \"Test DataLoader is None\"\n",
    "\n",
    "assert len(train_loader.dataset) > 0, \"Training dataset is empty\"\n",
    "assert len(val_loader.dataset) > 0, \"Validation dataset is empty\"\n",
    "assert len(test_loader.dataset) > 0, \"Test dataset is empty\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab191e9e-1e7f-455c-8338-75f7cb42f5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecaster\n",
      "\tL2: 1e-06\n",
      "\tLinear Window: 0\n",
      "\tLinear Shared Weights: False\n",
      "\tRevIN: False\n",
      "\tDecomposition: False\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Using Embedding: spatio-temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.1, Seq (max len = 5) 0.2, Skip All Drop 1.0\n",
      " *** Spacetimeformer (v1.5) Summary: *** \n",
      "\t\tModel Dim: 20\n",
      "\t\tFF Dim: 100\n",
      "\t\tEnc Layers: 2\n",
      "\t\tDec Layers: 2\n",
      "\t\tEmbed Dropout: 0.2\n",
      "\t\tFF Dropout: 0.3\n",
      "\t\tAttn Out Dropout: 0.0\n",
      "\t\tAttn Matrix Dropout: 0.0\n",
      "\t\tQKV Dropout: 0.0\n",
      "\t\tL2 Coeff: 1e-06\n",
      "\t\tWarmup Steps: 0\n",
      "\t\tNormalization Scheme: batch\n",
      "\t\tAttention Time Windows: 1\n",
      "\t\tShifted Time Windows: False\n",
      "\t\tPosition Emb Type: abs\n",
      "\t\tRecon Loss Imp: 0.0\n",
      " ***                                  *** \n",
      "Forecaster\n",
      "\tL2: 1e-06\n",
      "\tLinear Window: 0\n",
      "\tLinear Shared Weights: False\n",
      "\tRevIN: False\n",
      "\tDecomposition: False\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Using Embedding: spatio-temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.1, Seq (max len = 5) 0.2, Skip All Drop 1.0\n",
      " *** Spacetimeformer (v1.5) Summary: *** \n",
      "\t\tModel Dim: 20\n",
      "\t\tFF Dim: 20\n",
      "\t\tEnc Layers: 2\n",
      "\t\tDec Layers: 2\n",
      "\t\tEmbed Dropout: 0.2\n",
      "\t\tFF Dropout: 0.3\n",
      "\t\tAttn Out Dropout: 0.0\n",
      "\t\tAttn Matrix Dropout: 0.0\n",
      "\t\tQKV Dropout: 0.0\n",
      "\t\tL2 Coeff: 1e-06\n",
      "\t\tWarmup Steps: 0\n",
      "\t\tNormalization Scheme: batch\n",
      "\t\tAttention Time Windows: 1\n",
      "\t\tShifted Time Windows: False\n",
      "\t\tPosition Emb Type: abs\n",
      "\t\tRecon Loss Imp: 0.0\n",
      " ***                                  *** \n"
     ]
    }
   ],
   "source": [
    "scaler = bats_time_series.apply_scaling\n",
    "inverse_scaler = bats_time_series.reverse_scaling\n",
    "config.null_value = None\n",
    "config.pad_value = None\n",
    "\n",
    "# initialize the spacetimeformer model\n",
    "model = stf.spacetimeformer_model.Spacetimeformer_Forecaster(\n",
    "            d_x=x_dim,\n",
    "            d_yc=yc_dim,\n",
    "            d_yt=yt_dim,\n",
    "            max_seq_len=max_seq_len,\n",
    "            start_token_len=config.start_token_len,\n",
    "            attn_factor=config.attn_factor,\n",
    "            d_model=20,#config.d_model,\n",
    "            d_queries_keys=20,#config.d_qk,\n",
    "            d_values=20,#config.d_v,\n",
    "            n_heads=1,#config.n_heads,\n",
    "            e_layers=2,#config.enc_layers,\n",
    "            d_layers=2,#config.dec_layers,\n",
    "            d_ff=100,#config.d_ff,\n",
    "            dropout_emb=config.dropout_emb,\n",
    "            dropout_attn_out=config.dropout_attn_out,\n",
    "            dropout_attn_matrix=config.dropout_attn_matrix,\n",
    "            dropout_qkv=config.dropout_qkv,\n",
    "            dropout_ff=config.dropout_ff,\n",
    "            pos_emb_type=config.pos_emb_type,\n",
    "            use_final_norm=not config.no_final_norm,\n",
    "            global_self_attn=config.global_self_attn,\n",
    "            local_self_attn=config.local_self_attn,\n",
    "            global_cross_attn=config.global_cross_attn,\n",
    "            local_cross_attn=config.local_cross_attn,\n",
    "            performer_kernel=config.performer_kernel,\n",
    "            performer_redraw_interval=config.performer_redraw_interval,\n",
    "            attn_time_windows=config.attn_time_windows,\n",
    "            use_shifted_time_windows=config.use_shifted_time_windows,\n",
    "            norm=config.norm,\n",
    "            activation=config.activation,\n",
    "            init_lr=config.init_lr,\n",
    "            base_lr=config.base_lr,\n",
    "            warmup_steps=config.warmup_steps,\n",
    "            decay_factor=config.decay_factor,\n",
    "            initial_downsample_convs=config.initial_downsample_convs,\n",
    "            intermediate_downsample_convs=config.intermediate_downsample_convs,\n",
    "            embed_method=config.embed_method,\n",
    "            l2_coeff=config.l2_coeff,\n",
    "            loss=config.loss,\n",
    "            class_loss_imp=config.class_loss_imp,\n",
    "            recon_loss_imp=config.recon_loss_imp,\n",
    "            time_emb_dim=config.time_emb_dim,\n",
    "            null_value=config.null_value,\n",
    "            pad_value=config.pad_value,\n",
    "            linear_window=config.linear_window,\n",
    "            use_revin=config.use_revin,\n",
    "            linear_shared_weights=config.linear_shared_weights,\n",
    "            use_seasonal_decomp=config.use_seasonal_decomp,\n",
    "            use_val=not config.no_val,\n",
    "            use_time=not config.no_time,\n",
    "            use_space=not config.no_space,\n",
    "            use_given=not config.no_given,\n",
    "            recon_mask_skip_all=config.recon_mask_skip_all,\n",
    "            recon_mask_max_seq_len=config.recon_mask_max_seq_len,\n",
    "            recon_mask_drop_seq=config.recon_mask_drop_seq,\n",
    "            recon_mask_drop_standard=config.recon_mask_drop_standard,\n",
    "            recon_mask_drop_full=config.recon_mask_drop_full,\n",
    "        )\n",
    "\n",
    "model.set_inv_scaler(inverse_scaler);\n",
    "model.set_scaler(scaler);\n",
    "model.set_null_value(config.null_value);\n",
    "\n",
    "model = model.load_from_checkpoint(checkpoint_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a189ecc0-5355-4f9e-b434-6fed322dd876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spacetimeformer_Forecaster(\n",
       "  (spacetimeformer): Spacetimeformer(\n",
       "    (enc_embedding): Embedding(\n",
       "      (data_drop): Timesteps 0.05, Standard 0.1, Seq (max len = 5) 0.2, Skip All Drop 1.0\n",
       "      (time_emb): Time2Vec()\n",
       "      (local_emb): Embedding(32, 20)\n",
       "      (val_time_emb): Linear(in_features=7, out_features=20, bias=True)\n",
       "      (space_emb): Embedding(106, 20)\n",
       "      (given_emb): Embedding(2, 20)\n",
       "      (downsize_convs): ModuleList()\n",
       "    )\n",
       "    (dec_embedding): Embedding(\n",
       "      (time_emb): Time2Vec()\n",
       "      (local_emb): Embedding(32, 20)\n",
       "      (val_time_emb): Linear(in_features=7, out_features=20, bias=True)\n",
       "      (space_emb): Embedding(106, 20)\n",
       "      (given_emb): Embedding(2, 20)\n",
       "      (downsize_convs): ModuleList()\n",
       "    )\n",
       "    (encoder): Encoder(\n",
       "      (attn_layers): ModuleList(\n",
       "        (0): EncoderLayer(\n",
       "          (local_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (global_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (conv1): Conv1d(20, 20, kernel_size=(1,), stride=(1,))\n",
       "          (conv2): Conv1d(20, 20, kernel_size=(1,), stride=(1,))\n",
       "          (norm1): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm2): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm3): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (dropout_ff): Dropout(p=0.3, inplace=False)\n",
       "          (dropout_attn_out): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): EncoderLayer(\n",
       "          (local_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (global_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (conv1): Conv1d(20, 20, kernel_size=(1,), stride=(1,))\n",
       "          (conv2): Conv1d(20, 20, kernel_size=(1,), stride=(1,))\n",
       "          (norm1): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm2): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm3): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (dropout_ff): Dropout(p=0.3, inplace=False)\n",
       "          (dropout_attn_out): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (conv_layers): ModuleList()\n",
       "      (norm_layer): Normalization(\n",
       "        (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (emb_dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): DecoderLayer(\n",
       "          (local_self_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (global_self_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (global_cross_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (local_cross_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (conv1): Conv1d(20, 20, kernel_size=(1,), stride=(1,))\n",
       "          (conv2): Conv1d(20, 20, kernel_size=(1,), stride=(1,))\n",
       "          (norm1): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm2): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm3): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm4): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm5): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (dropout_ff): Dropout(p=0.3, inplace=False)\n",
       "          (dropout_attn_out): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): DecoderLayer(\n",
       "          (local_self_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (global_self_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (global_cross_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (local_cross_attention): AttentionLayer(\n",
       "            (inner_attention): PerformerAttention(\n",
       "              (kernel_fn): ReLU()\n",
       "            )\n",
       "            (query_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (key_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (value_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (out_projection): Linear(in_features=20, out_features=20, bias=True)\n",
       "            (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (conv1): Conv1d(20, 20, kernel_size=(1,), stride=(1,))\n",
       "          (conv2): Conv1d(20, 20, kernel_size=(1,), stride=(1,))\n",
       "          (norm1): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm2): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm3): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm4): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (norm5): Normalization(\n",
       "            (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (dropout_ff): Dropout(p=0.3, inplace=False)\n",
       "          (dropout_attn_out): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_layer): Normalization(\n",
       "        (norm): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (emb_dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (forecaster): Linear(in_features=20, out_features=1, bias=True)\n",
       "    (reconstructor): Linear(in_features=20, out_features=1, bias=True)\n",
       "    (classifier): Linear(in_features=20, out_features=106, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## so the model succesfully loads and everything, now all I need to do is to figure out a way to parse through the input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b0375-a054-4c5f-a3b0-c04130c21e00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
