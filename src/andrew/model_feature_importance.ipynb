{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74cdd3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import spacetimeformer as stf\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf51a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../bats_transformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a70a52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.bats_dataset import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c219f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../../bats_transformer/models/daytime_files_new_10_11/models_31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50b719bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecaster\n",
      "\tL2: 0.001\n",
      "\tLinear Window: 0\n",
      "\tLinear Shared Weights: False\n",
      "\tRevIN: False\n",
      "\tDecomposition: False\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (key_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (value_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (out_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (key_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (value_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (out_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (key_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (value_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (out_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (key_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (value_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (out_projection): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Using Embedding: spatio-temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.2, Seq (max len = 5) 0.1, Skip All Drop 1.0\n",
      " *** Spacetimeformer (v1.5) Summary: *** \n",
      "\t\tModel Dim: 200\n",
      "\t\tFF Dim: 800\n",
      "\t\tEnc Layers: 2\n",
      "\t\tDec Layers: 2\n",
      "\t\tEmbed Dropout: 0.1\n",
      "\t\tFF Dropout: 0.2\n",
      "\t\tAttn Out Dropout: 0.0\n",
      "\t\tAttn Matrix Dropout: 0.0\n",
      "\t\tQKV Dropout: 0.0\n",
      "\t\tL2 Coeff: 0.001\n",
      "\t\tWarmup Steps: 1000\n",
      "\t\tNormalization Scheme: batch\n",
      "\t\tAttention Time Windows: 1\n",
      "\t\tShifted Time Windows: True\n",
      "\t\tPosition Emb Type: abs\n",
      "\t\tRecon Loss Imp: 0\n",
      " ***                                  *** \n",
      "Forecaster\n",
      "\tL2: 1e-06\n",
      "\tLinear Window: 0\n",
      "\tLinear Shared Weights: False\n",
      "\tRevIN: False\n",
      "\tDecomposition: False\n",
      "GlobalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "GlobalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalSelfAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "LocalCrossAttn: AttentionLayer(\n",
      "  (inner_attention): PerformerAttention(\n",
      "    (kernel_fn): ReLU()\n",
      "  )\n",
      "  (query_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (key_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (value_projection): Linear(in_features=100, out_features=20, bias=True)\n",
      "  (out_projection): Linear(in_features=20, out_features=100, bias=True)\n",
      "  (dropout_qkv): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Using Embedding: spatio-temporal\n",
      "Time Emb Dim: 6\n",
      "Space Embedding: True\n",
      "Time Embedding: True\n",
      "Val Embedding: True\n",
      "Given Embedding: True\n",
      "Null Value: None\n",
      "Pad Value: None\n",
      "Reconstruction Dropout: Timesteps 0.05, Standard 0.1, Seq (max len = 5) 0.2, Skip All Drop 1.0\n",
      " *** Spacetimeformer (v1.5) Summary: *** \n",
      "\t\tModel Dim: 100\n",
      "\t\tFF Dim: 400\n",
      "\t\tEnc Layers: 2\n",
      "\t\tDec Layers: 2\n",
      "\t\tEmbed Dropout: 0.2\n",
      "\t\tFF Dropout: 0.3\n",
      "\t\tAttn Out Dropout: 0.0\n",
      "\t\tAttn Matrix Dropout: 0.0\n",
      "\t\tQKV Dropout: 0.0\n",
      "\t\tL2 Coeff: 1e-06\n",
      "\t\tWarmup Steps: 0\n",
      "\t\tNormalization Scheme: batch\n",
      "\t\tAttention Time Windows: 1\n",
      "\t\tShifted Time Windows: False\n",
      "\t\tPosition Emb Type: abs\n",
      "\t\tRecon Loss Imp: 0.0\n",
      " ***                                  *** \n"
     ]
    }
   ],
   "source": [
    "model = stf.spacetimeformer_model.Spacetimeformer_Forecaster(max_seq_len = 54).load_from_checkpoint(checkpoint_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a7ab522",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_cols = [\"FreqLedge\",\"AmpK@end\", \"Fc\", \"FBak15dB  \", \"FBak32dB\", \"EndF\", \"FBak20dB\", \"LowFreq\", \"Bndw20dB\", \n",
    "               \"CallsPerSec\", \"EndSlope\", \"SteepestSlope\", \"StartSlope\", \"Bndw15dB\", \"HiFtoUpprKnSlp\", \"HiFtoKnSlope\", \n",
    "               \"DominantSlope\", \"Bndw5dB\", \"PreFc500\", \"PreFc1000\", \"PreFc3000\", \"KneeToFcSlope\", \"TotalSlope\", \n",
    "               \"PreFc250\", \"CallDuration\", \"CummNmlzdSlp\", \"DurOf32dB\", \"SlopeAtFc\", \"LdgToFcSlp\", \"DurOf20dB\", \"DurOf15dB\", \n",
    "               \"TimeFromMaxToFc\", \"KnToFcDur\", \"HiFtoFcExpAmp\", \"AmpKurtosis\", \"LowestSlope\", \"KnToFcDmp\", \"HiFtoKnExpAmp\", \n",
    "               \"DurOf5dB\", \"KnToFcExpAmp\", \"RelPwr3rdTo1st\", \"LnExpB_StartAmp\", \"Filter\", \"HiFtoKnDmp\", \"LnExpB_EndAmp\", \n",
    "               \"HiFtoFcDmp\", \"AmpSkew\", \"LedgeDuration\", \"KneeToFcResidue\", \"PreFc3000Residue\", \"AmpGausR2\", \"PreFc1000Residue\", \n",
    "               \"Amp1stMean\", \"LdgToFcExp\", \"FcMinusEndF\", \"Amp4thMean\", \"HiFtoUpprKnExp\", \"HiFtoKnExp\", \"KnToFcExp\", \"UpprKnToKnExp\", \n",
    "               \"Kn-FcCurviness\", \"Amp2ndMean\", \"Quality\", \"HiFtoFcExp\", \"LnExpA_EndAmp\", \"RelPwr2ndTo1st\", \"LnExpA_StartAmp\", \n",
    "               \"HiFminusStartF\", \"Amp3rdMean\", \"PreFc500Residue\", \"Kn-FcCurvinessTrndSlp\", \"PreFc250Residue\", \"AmpVariance\", \"AmpMoment\", \n",
    "               \"meanKn-FcCurviness\", \"MinAccpQuality\", \"AmpEndLn60ExpC\", \"AmpStartLn60ExpC\", \"Preemphasis\", \"MaxSegLnght\" ,\"Max#CallsConsidered\" ]\n",
    "ignore_cols += [\"Filename\", \"NextDirUp\", 'Path', 'Version', 'Filter', 'Preemphasis', 'MaxSegLnght', \"ParentDir\", \"file_id\", \"chirp_idx\", \"split\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44f94653",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = stf.data.DataModule(\n",
    "    datasetCls = BatsCSVDatasetWithMetadata,\n",
    "    dataset_kwargs = {\n",
    "        \"root_path\": \"../../bats_transformer/data/daytime_files_new/splits\",\n",
    "        \"prefix\": \"split\",\n",
    "        \"ignore_cols\": ignore_cols,\n",
    "        \"metadata_cols\": [\"file_id\", \"chirp_idx\"],\n",
    "        \"time_col_name\": \"TimeIndex\",\n",
    "        \"val_split\": 0.05,\n",
    "        \"test_split\": 0.05,\n",
    "        \"context_points\": None,\n",
    "        \"target_points\": 1,\n",
    "    },\n",
    "    batch_size=64,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38d31af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dda37b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 31, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_data))  # Get a batch of data\n",
    "batch = batch[0]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "856fb63a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 3 required positional arguments: 'y_c', 'x_t', and 'y_t'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming you have a sample input batch 'X' for the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Replace 'X' with your actual input data (as a numpy array or torch tensor)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(batch)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# To visualize feature importance for the first sample\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bats/lib/python3.8/site-packages/shap/explainers/_deep/__init__.py:86\u001b[0m, in \u001b[0;36mDeepExplainer.__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m TFDeep(model, data, session, learning_phase_flags)\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mPyTorchDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mexpected_value\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m=\u001b[39m framework\n",
      "File \u001b[0;32m~/miniconda3/envs/bats/lib/python3.8/site-packages/shap/explainers/_deep/deep_pytorch.py:58\u001b[0m, in \u001b[0;36mPyTorchDeep.__init__\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 58\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# also get the device everything is running on\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mdevice\n",
      "File \u001b[0;32m~/miniconda3/envs/bats/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 3 required positional arguments: 'y_c', 'x_t', and 'y_t'"
     ]
    }
   ],
   "source": [
    "# Assuming you have a sample input batch 'X' for the model\n",
    "# Replace 'X' with your actual input data (as a numpy array or torch tensor)\n",
    "\n",
    "explainer = shap.DeepExplainer(model, batch)\n",
    "shap_values = explainer.shap_values(batch)\n",
    "\n",
    "# To visualize feature importance for the first sample\n",
    "shap.summary_plot(shap_values, batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
